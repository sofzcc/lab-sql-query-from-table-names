{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_TtALUgWHg5",
        "outputId": "93764206-4abb-4b57-a32c-372152bf64f7"
      },
      "id": "X_TtALUgWHg5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/325.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
      "metadata": {
        "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6"
      },
      "source": [
        "# SQL query from table names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
      "metadata": {
        "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
      },
      "source": [
        "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
      "metadata": {
        "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY  = userdata.get('OPENAI_API_KEY_Ironhack')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
      "metadata": {
        "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_OAI(user_message):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        "\n",
        ")\n",
        "    context = []\n",
        "    context.append({'role':'system', \"content\": user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=context,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
      "metadata": {
        "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
        "outputId": "e456bc2d-3809-4a45-8223-4668f845f9aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       table                                         definition\n",
            "0  employees  Table storing employee information including n...\n",
            "1     salary  Table storing salary details for each employee...\n",
            "2    studies  Table storing educational studies data includi...\n"
          ]
        }
      ],
      "source": [
        "#Definition of the tables.\n",
        "import pandas as pd\n",
        "\n",
        "# Table and definitions sample\n",
        "data = {'table': ['employees', 'salary', 'studies'],\n",
        "        'definition': [\n",
        "            'Table storing employee information including name, ID, department, and contact details.',\n",
        "            'Table storing salary details for each employee including annual salary, bonuses, and benefits.',\n",
        "            'Table storing educational studies data including institution name, degree obtained, and field of study.'\n",
        "        ]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
      "metadata": {
        "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
      },
      "outputs": [],
      "source": [
        "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
      "metadata": {
        "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
        "outputId": "75375aaf-5d0c-4efa-8a32-eff15a7b5913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "employees: Table storing employee information including name, ID, department, and contact details.\n",
            "salary: Table storing salary details for each employee including annual salary, bonuses, and benefits.\n",
            "studies: Table storing educational studies data including institution name, degree obtained, and field of study.\n"
          ]
        }
      ],
      "source": [
        "print(text_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
      "metadata": {
        "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
      },
      "outputs": [],
      "source": [
        "prompt_question_tables = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "###Tables\n",
        "{tables}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a json format.\n",
        "###User Questyion:\n",
        "{question}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
      "metadata": {
        "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
      },
      "outputs": [],
      "source": [
        "#Creating the prompt, with the user questions and the tables definitions.\n",
        "pqt1 = prompt_question_tables.format(tables=text_tables, question='Which employees received a salary increase last year?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
      "metadata": {
        "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
        "outputId": "88d34045-2640-4202-e437-db7571587d83",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
      "metadata": {
        "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
      },
      "outputs": [],
      "source": [
        "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
        "                                     question='Can you provide a brief description of each table in your database?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
      "metadata": {
        "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
        "outputId": "5784cbfe-9b7c-44e6-ba40-45e474149638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
      "metadata": {
        "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describing the tables in a JSON Format"
      ],
      "metadata": {
        "id": "y-Z-66UGZPeT"
      },
      "id": "y-Z-66UGZPeT"
    },
    {
      "cell_type": "code",
      "source": [
        "tables_dict = df.set_index('table')['definition'].to_dict()\n",
        "output_json = {\"tables\": tables_dict}\n",
        "\n",
        "print(output_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRirfC_oZH29",
        "outputId": "93839008-cd83-4ade-b9ed-b58a6600e9d2"
      },
      "id": "eRirfC_oZH29",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tables': {'employees': 'Table storing employee information including name, ID, department, and contact details.', 'salary': 'Table storing salary details for each employee including annual salary, bonuses, and benefits.', 'studies': 'Table storing educational studies data including institution name, degree obtained, and field of study.'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "\n",
        "# Function to call the OpenAI model\n",
        "def get_response(user_message):\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    context = []\n",
        "    context.append({'role': 'system', \"content\": user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=context,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Define data for cat-related tables and their definitions\n",
        "data_cats = {'table': ['cat breeds', 'dietary restrictions', 'food brands'],\n",
        "             'definition': [\n",
        "                 'Table storing information about different breeds of cats including characteristics, origins, and appearance.',\n",
        "                 'Table storing dietary restrictions for cats including foods that are harmful or beneficial for feline health.',\n",
        "                 'Table storing brands and types of cat food available in the market, their ingredients, and nutritional values.'\n",
        "             ]}\n",
        "\n",
        "# Create a DataFrame for cat-related data\n",
        "df_cats = pd.DataFrame(data_cats)\n",
        "\n",
        "# Construct text representation of tables\n",
        "text_tables_cats = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df_cats.iterrows()])\n",
        "\n",
        "# Prompt template with updated cat-related topics\n",
        "prompt_question_tables_cats = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "### Tables\n",
        "{text_tables_cats}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a json format.\n",
        "### User Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Prompt 1 \\n\")\n",
        "# Create the prompt with the user question and tables definitions\n",
        "pqt1_cats = prompt_question_tables_cats.format(text_tables_cats=text_tables_cats, question='Which cat breeds are suitable for hypoallergenic households?')\n",
        "\n",
        "# Call the OpenAI model with the prepared prompt\n",
        "print(return_OAI(pqt1_cats))\n",
        "\n",
        "print(\"\\n Prompt 2 \\n\")\n",
        "\n",
        "# Create the prompt with the user question and tables definitions\n",
        "pqt2_cats = prompt_question_tables_cats.format(text_tables_cats=text_tables_cats, question='Which cat food brands are more common?')\n",
        "\n",
        "# Call the OpenAI model with the prepared prompt\n",
        "print(return_OAI(pqt2_cats))\n",
        "\n",
        "print(\"\\n Prompt 3\")\n",
        "\n",
        "# Create the prompt with the user question and tables definitions\n",
        "pqt3_cats = prompt_question_tables_cats.format(text_tables_cats=text_tables_cats, question='What does a siamese cat eat?')\n",
        "\n",
        "# Call the OpenAI model with the prepared prompt\n",
        "print(return_OAI(pqt3_cats))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQRh-FqTZYzM",
        "outputId": "83d9adcf-d350-4993-d4ef-e7dcca3c2db3"
      },
      "id": "CQRh-FqTZYzM",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt 1 \n",
            "\n",
            "{\n",
            "    \"tables\": [\"cat breeds\"]\n",
            "}\n",
            "\n",
            " Prompt 2 \n",
            "\n",
            "{\n",
            "  \"tables\": [\"food brands\"]\n",
            "}\n",
            "\n",
            " Prompt 3\n",
            "{\n",
            "  \"tables\": [\"cat breeds\", \"dietary restrictions\", \"food brands\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_cats = \"\"\"\n",
        "Which cat breeds are suitable for hypoallergenic households?\n",
        "\"\"\"\n",
        "\n",
        "# Get response from OpenAI model\n",
        "response_cats = get_response(prompt_cats)\n",
        "\n",
        "# Print the model's answer\n",
        "print(\"Model's Answer:\", response_cats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwyXL41bav3o",
        "outputId": "e57ff9b8-e014-4cc5-ac58-c5ed2b03b9f4"
      },
      "id": "dwyXL41bav3o",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's Answer: Some cat breeds that are considered suitable for hypoallergenic households include:\n",
            "\n",
            "1. Balinese\n",
            "2. Russian Blue\n",
            "3. Siberian\n",
            "4. Sphynx\n",
            "5. Devon Rex\n",
            "6. Cornish Rex\n",
            "7. Bengal\n",
            "8. Javanese\n",
            "9. Oriental Shorthair\n",
            "10. Siamese\n",
            "\n",
            "These breeds are known to produce fewer allergens or shed less dander, making them a better choice for individuals with allergies to cats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I explored using OpenAI's GPT-3.5 model to answer questions about cats, focusing on topics like hypoallergenic breeds and common cat food brands. I set up structured data for cat breeds, dietary restrictions, and food brands, then asked the model various questions to see how well it responded.\n",
        "\n",
        "The model performed well when I asked clear and specific questions. For example, when I inquired about hypoallergenic cat breeds, it correctly identified that information from the \"cat breeds\" data table would be useful. It provided structured answers based on the data I provided, which was encouraging.\n",
        "\n",
        "However, there were times when the model seemed confused or gave vague responses. This typically happened with more open-ended questions or when the question required information beyond what the data covered.\n",
        "\n",
        "From this experience, I learned the importance of crafting precise prompts with well-defined data. The model’s responses are directly influenced by the information and context provided in the prompt. For accurate answers, it’s essential to structure queries carefully."
      ],
      "metadata": {
        "id": "iFYwvoRlbsnf"
      },
      "id": "iFYwvoRlbsnf"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}